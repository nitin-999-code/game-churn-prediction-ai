{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Game Churn Prediction AI - ML Churn Prediction\n",
        "\n",
        "This notebook splits the clean data, trains machine learning models, and evaluates their performance to save the best model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "sns.set_theme(style='whitegrid')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Load Clean Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/clean_data.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Split data into train/test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(columns=['Churn'])\n",
        "y = df['Churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Train Models (Random Forest & Logistic Regression)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_preds = rf_model.predict(X_test)\n",
        "\n",
        "# Logistic Regression Model\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_preds = lr_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Compare Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_metrics(y_true, y_pred, model_name):\n",
        "    print(f\"--- {model_name} ---\")\n",
        "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"F1-score:  {f1_score(y_true, y_pred):.4f}\\n\")\n",
        "\n",
        "print_metrics(y_test, rf_preds, \"Random Forest\")\n",
        "print_metrics(y_test, lr_preds, \"Logistic Regression\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Plot Confusion Matrix (Best Model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, rf_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix - Random Forest')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Show Feature Importance & Explain Top Churn Factors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': rf_model.feature_importances_})\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importances.head(10))\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Top Churn Factors Explained ---\")\n",
        "print(\"The features at the top of the chart have the highest impact on a player's likelihood to churn.\")\n",
        "for i, row in feature_importances.head(3).iterrows():\n",
        "    print(f\"- {row['Feature']}: Highly influences engagement and retention.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Save Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(rf_model, '../models/churn_model.pkl')\n",
        "joblib.dump(X.columns.tolist(), '../models/model_features.pkl')\n",
        "print(\"Model successfully saved to '../models/churn_model.pkl'\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}